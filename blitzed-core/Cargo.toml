[package]
name = "blitzed-core"
version = "0.1.0"
edition = "2021"
authors.workspace = true
description = "Core optimization engine for edge AI model deployment"
license.workspace = true
repository.workspace = true
homepage.workspace = true
keywords = ["machine-learning", "edge-ai", "optimization", "quantization", "neural-networks"]
categories = ["science", "algorithms", "embedded"]

[dependencies]
# Core ML dependencies
candle-core = { workspace = true }
candle-nn = { workspace = true }
ort = { workspace = true, optional = true }
ndarray = { workspace = true, optional = true }
tch = { version = "0.15", optional = true }

# Serialization and data
serde = { workspace = true }
serde_json = { workspace = true }
bincode = { workspace = true }

# Performance and async
tokio = { workspace = true }
rayon = { workspace = true }

# Error handling
anyhow = { workspace = true }
thiserror = { workspace = true }
log = { workspace = true }
env_logger = { workspace = true }

# Configuration
config = { workspace = true }
toml = { workspace = true }

# Date/time utilities
chrono = { workspace = true }

# HTTP client for model downloads
reqwest = { version = "0.11", features = ["json", "stream"] }

# Stream utilities
tokio-stream = "0.1"
futures = "0.3"

# Random number generation
rand = "0.8"

# Command line interface
clap = { version = "4.0", features = ["derive"] }

[dev-dependencies]
approx = { workspace = true }
tempfile = { workspace = true }
env_logger = { workspace = true }
criterion = { version = "0.5", features = ["html_reports"] }

[[bench]]
name = "optimization_bench"
harness = false

[features]
default = ["onnx", "pytorch", "quantization"]
onnx = ["ort", "ndarray"]
pytorch = ["tch"]
quantization = []
pruning = []
distillation = []
hardware-targets = []
slow-tests = []  # Enable expensive/slow tests for comprehensive CI