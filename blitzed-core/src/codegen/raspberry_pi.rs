// Copyright 2025 Gibran Rodriguez <brangi000@gmail.com>
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Raspberry Pi-specific code generator

use super::{CodeGenerator, GeneratedCode};
use crate::{Model, Result};
use std::path::Path;

/// Raspberry Pi code generator
pub struct RaspberryPiCodeGen;

impl RaspberryPiCodeGen {
    pub fn new() -> Self {
        Self
    }
}

impl CodeGenerator for RaspberryPiCodeGen {
    fn generate(&self, _model: &Model, output_dir: &Path) -> Result<GeneratedCode> {
        std::fs::create_dir_all(output_dir)?;

        let main_content = format!(r#"// Generated by Blitzed v{}
// Raspberry Pi model deployment

#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <time.h>
#include <unistd.h>
#include <sys/time.h>
#include "blitzed_model.h"

// Threading configuration for multi-core inference
#define MAX_THREADS 4
#define INFERENCE_ITERATIONS 100

typedef struct {{
    int thread_id;
    model_input_t* input;
    model_output_t* output;
    double* inference_times;
    int iterations;
}} thread_data_t;

// Global model initialization
static int model_initialized = 0;
static pthread_mutex_t model_mutex = PTHREAD_MUTEX_INITIALIZER;

// Get current time in microseconds
static double get_time_us() {{
    struct timeval tv;
    gettimeofday(&tv, NULL);
    return tv.tv_sec * 1000000.0 + tv.tv_usec;
}}

// Worker thread for inference
void* inference_worker(void* arg) {{
    thread_data_t* data = (thread_data_t*)arg;
    
    printf("[Thread %d] Starting %d inference iterations\\n", data->thread_id, data->iterations);
    
    for (int i = 0; i < data->iterations; i++) {{
        // Generate random input data
        for (int j = 0; j < MODEL_INPUT_SIZE; j++) {{
            data->input[j] = (model_input_t)(rand() % 256 - 128);
        }}
        
        double start_time = get_time_us();
        int result = model_predict(data->input, data->output);
        double end_time = get_time_us();
        
        if (result == 0) {{
            data->inference_times[i] = end_time - start_time;
        }} else {{
            printf("[Thread %d] Inference %d failed\\n", data->thread_id, i);
            data->inference_times[i] = -1.0;
        }}
        
        // Small delay to prevent thermal throttling
        if (i % 10 == 0) {{
            usleep(1000); // 1ms delay every 10 iterations
        }}
    }}
    
    printf("[Thread %d] Completed inference iterations\\n", data->thread_id);
    return NULL;
}}

// Benchmark single-threaded performance
void benchmark_single_thread() {{
    printf("\\n=== Single-threaded Benchmark ===\\n");
    
    model_input_t* input = (model_input_t*)malloc(MODEL_INPUT_SIZE * sizeof(model_input_t));
    model_output_t* output = (model_output_t*)malloc(MODEL_OUTPUT_SIZE * sizeof(model_output_t));
    
    if (!input || !output) {{
        printf("Failed to allocate memory for single-threaded benchmark\\n");
        return;
    }}
    
    double total_time = 0.0;
    int successful_runs = 0;
    
    for (int i = 0; i < INFERENCE_ITERATIONS; i++) {{
        // Generate sample input
        for (int j = 0; j < MODEL_INPUT_SIZE; j++) {{
            input[j] = (model_input_t)(rand() % 256 - 128);
        }}
        
        double start_time = get_time_us();
        int result = model_predict(input, output);
        double end_time = get_time_us();
        
        if (result == 0) {{
            total_time += (end_time - start_time);
            successful_runs++;
            
            if (i % 20 == 0) {{
                printf("Iteration %d: %.2f μs\\n", i, end_time - start_time);
            }}
        }}
    }}
    
    if (successful_runs > 0) {{
        double avg_time = total_time / successful_runs;
        double fps = 1000000.0 / avg_time;
        printf("Average inference time: %.2f μs (%.2f FPS)\\n", avg_time, fps);
        printf("Total time: %.2f ms\\n", total_time / 1000.0);
        printf("Successful runs: %d/%d\\n", successful_runs, INFERENCE_ITERATIONS);
    }}
    
    free(input);
    free(output);
}}

// Benchmark multi-threaded performance
void benchmark_multi_thread() {{
    printf("\\n=== Multi-threaded Benchmark ===\\n");
    
    int num_cores = sysconf(_SC_NPROCESSORS_ONLN);
    int num_threads = (num_cores > MAX_THREADS) ? MAX_THREADS : num_cores;
    
    printf("Detected %d CPU cores, using %d threads\\n", num_cores, num_threads);
    
    pthread_t threads[MAX_THREADS];
    thread_data_t thread_data[MAX_THREADS];
    
    // Prepare thread data
    for (int t = 0; t < num_threads; t++) {{
        thread_data[t].thread_id = t;
        thread_data[t].input = (model_input_t*)malloc(MODEL_INPUT_SIZE * sizeof(model_input_t));
        thread_data[t].output = (model_output_t*)malloc(MODEL_OUTPUT_SIZE * sizeof(model_output_t));
        thread_data[t].inference_times = (double*)malloc(INFERENCE_ITERATIONS * sizeof(double));
        thread_data[t].iterations = INFERENCE_ITERATIONS / num_threads;
        
        if (!thread_data[t].input || !thread_data[t].output || !thread_data[t].inference_times) {{
            printf("Failed to allocate memory for thread %d\\n", t);
            return;
        }}
    }}
    
    // Start threads
    double start_time = get_time_us();
    for (int t = 0; t < num_threads; t++) {{
        pthread_create(&threads[t], NULL, inference_worker, &thread_data[t]);
    }}
    
    // Wait for all threads to complete
    for (int t = 0; t < num_threads; t++) {{
        pthread_join(threads[t], NULL);
    }}
    double end_time = get_time_us();
    
    // Calculate statistics
    double total_time = 0.0;
    int total_successful = 0;
    
    for (int t = 0; t < num_threads; t++) {{
        for (int i = 0; i < thread_data[t].iterations; i++) {{
            if (thread_data[t].inference_times[i] > 0) {{
                total_time += thread_data[t].inference_times[i];
                total_successful++;
            }}
        }}
    }}
    
    if (total_successful > 0) {{
        double avg_time = total_time / total_successful;
        double total_wall_time = (end_time - start_time) / 1000.0; // Convert to ms
        double throughput = total_successful / (total_wall_time / 1000.0); // Inferences per second
        
        printf("Multi-threaded results:\\n");
        printf("  Average inference time: %.2f μs\\n", avg_time);
        printf("  Total wall time: %.2f ms\\n", total_wall_time);
        printf("  Total inferences: %d\\n", total_successful);
        printf("  Throughput: %.2f inferences/second\\n", throughput);
        printf("  Parallel efficiency: %.1f%%\\n", 
               (throughput * avg_time / 1000000.0) / num_threads * 100.0);
    }}
    
    // Cleanup
    for (int t = 0; t < num_threads; t++) {{
        free(thread_data[t].input);
        free(thread_data[t].output);
        free(thread_data[t].inference_times);
    }}
}}

// Monitor system temperature (Raspberry Pi specific)
void monitor_temperature() {{
    FILE* temp_file = fopen("/sys/class/thermal/thermal_zone0/temp", "r");
    if (temp_file) {{
        int temp_millidegrees;
        if (fscanf(temp_file, "%d", &temp_millidegrees) == 1) {{
            float temp_celsius = temp_millidegrees / 1000.0;
            printf("CPU Temperature: %.1f°C", temp_celsius);
            
            if (temp_celsius > 80.0) {{
                printf(" (WARNING: High temperature!)");
            }} else if (temp_celsius > 70.0) {{
                printf(" (Warm)");
            }}
            printf("\\n");
        }}
        fclose(temp_file);
    }} else {{
        printf("Temperature monitoring not available\\n");
    }}
}}

int main() {{
    printf("Blitzed Model Benchmark on Raspberry Pi\\n");
    printf("Generated by Blitzed v{}\\n\\n");
    
    // Initialize random seed
    srand(time(NULL));
    
    // Monitor initial temperature
    monitor_temperature();
    
    // Initialize model
    printf("Initializing model...\\n");
    if (model_init() != 0) {{
        printf("Model initialization failed\\n");
        return 1;
    }}
    
    printf("Model initialized successfully\\n");
    
    // Run benchmarks
    benchmark_single_thread();
    benchmark_multi_thread();
    
    // Monitor final temperature
    printf("\\n");
    monitor_temperature();
    
    printf("\\nBenchmark completed.\\n");
    return 0;
}}
"#, crate::VERSION, crate::VERSION);

        let makefile_content = format!(r#"# Generated by Blitzed v{}
# Raspberry Pi Makefile

CC = gcc
CFLAGS = -O3 -Wall -Wextra -std=c99 -march=native -mtune=native
LDFLAGS = -lpthread -lm

# Detect Raspberry Pi model for optimizations
RPI_MODEL := $(shell cat /proc/device-tree/model 2>/dev/null | tr ' ' '_' | tr '[:upper:]' '[:lower:]' || echo "unknown")

# Optimization flags based on Pi model
ifeq ($(findstring pi_4,$(RPI_MODEL)),pi_4)
    CFLAGS += -mcpu=cortex-a72 -DRPI_4B=1
else ifeq ($(findstring pi_3,$(RPI_MODEL)),pi_3)
    CFLAGS += -mcpu=cortex-a53 -DRPI_3=1
else ifeq ($(findstring pi_zero_2,$(RPI_MODEL)),pi_zero_2)
    CFLAGS += -mcpu=cortex-a53 -DRPI_ZERO2=1
else
    CFLAGS += -mcpu=arm1176jzf-s -DRPI_LEGACY=1
endif

# Source files
SOURCES = main.c blitzed_model.c
OBJECTS = $(SOURCES:.c=.o)
TARGET = blitzed_benchmark

.PHONY: all clean install run benchmark

all: $(TARGET)

$(TARGET): $(OBJECTS)
	$(CC) $(OBJECTS) -o $@ $(LDFLAGS)

%.o: %.c
	$(CC) $(CFLAGS) -c $< -o $@

clean:
	rm -f $(OBJECTS) $(TARGET)

install: $(TARGET)
	sudo cp $(TARGET) /usr/local/bin/
	sudo chmod +x /usr/local/bin/$(TARGET)

run: $(TARGET)
	./$(TARGET)

benchmark: $(TARGET)
	@echo "Running comprehensive benchmark..."
	@echo "CPU Info:"
	@cat /proc/cpuinfo | grep "model name" | head -n1
	@echo "Memory Info:"
	@free -h
	@echo ""
	./$(TARGET)

# Performance monitoring
monitor:
	@echo "=== System Performance Monitor ==="
	@echo "CPU Temperature:"
	@cat /sys/class/thermal/thermal_zone0/temp | awk '{{print $$1/1000 "°C"}}'
	@echo "CPU Frequency:"
	@cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq | awk '{{print $$1/1000 "MHz"}}'
	@echo "Memory Usage:"
	@free -h
	@echo "CPU Usage:"
	@top -bn1 | grep "Cpu(s)" | awk '{{print $$2}}' | awk -F'%' '{{print $$1}}' | awk '{{print "CPU: " $$1 "%"}}'

# Help target
help:
	@echo "Available targets:"
	@echo "  all       - Build the benchmark"
	@echo "  clean     - Remove build files"
	@echo "  install   - Install to /usr/local/bin"
	@echo "  run       - Run the benchmark"
	@echo "  benchmark - Run with system info"
	@echo "  monitor   - Show system performance"
	@echo "  help      - Show this help"
"#, crate::VERSION);

        let main_path = output_dir.join("main.c");
        let makefile_path = output_dir.join("Makefile");
        
        std::fs::write(&main_path, &main_content)?;
        std::fs::write(&makefile_path, &makefile_content)?;

        Ok(GeneratedCode {
            implementation_file: main_content,
            header_file: None,
            example_file: Some(main_path.to_string_lossy().to_string()),
            build_config: Some(makefile_path.to_string_lossy().to_string()),
            dependencies: vec!["pthread".to_string(), "gcc".to_string()],
        })
    }

    fn target_name(&self) -> &str {
        "raspberry_pi"
    }

    fn dependencies(&self) -> Vec<String> {
        vec!["pthread".to_string(), "gcc".to_string()]
    }
}

impl Default for RaspberryPiCodeGen {
    fn default() -> Self {
        Self::new()
    }
}